from typing import List, Dict
import google.generativeai as genai
from langchain_google_genai import ChatGoogleGenerativeAI
import logging
import time

class DeepReasoning:
    def __init__(self, key_manager):
        self.key_manager = key_manager
        self.setup_model()
        
    def setup_model(self):
        api_key = self.key_manager.get_api_key()
        self.model = ChatGoogleGenerativeAI(
            model="gemini-1.5-pro",
            google_api_key=api_key,
            temperature=0.1,
            max_output_tokens=2048,
        )

    def deep_think(self, question: str, context: str) -> Dict:
        """
        Thá»±c hiá»‡n quÃ¡ trÃ¬nh suy nghÄ© sÃ¢u dá»±a trÃªn context cÃ³ sáºµn
        """
        # Kiá»ƒm tra context trÆ°á»›c
        if not context or context.isspace():
            return {
                "thoughts": [{
                    "step": "Kiá»ƒm tra thÃ´ng tin",
                    "thought": "ğŸ” Äang kiá»ƒm tra nguá»“n thÃ´ng tin...",
                    "content": "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u."
                }],
                "final_answer": "TÃ´i khÃ´ng cÃ³ Ä‘á»§ thÃ´ng tin Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i nÃ y."
            }

        # Log the context for debugging
        logging.info(f"Ngá»¯ cáº£nh: {context}")

        # Sá»­ dá»¥ng má»™t prompt duy nháº¥t Ä‘á»ƒ kiá»ƒm tra Ä‘á»™ liÃªn quan
        relevance_prompt = f"""Dá»±a trÃªn context sau:
        {context}
        
        HÃ£y cho biáº¿t liá»‡u context cÃ³ chá»©a Ä‘á»§ thÃ´ng tin Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i: "{question}" khÃ´ng? 
        Náº¿u khÃ´ng, hÃ£y tráº£ lá»i "TÃ´i khÃ´ng biáº¿t".
        CHÃš Ã: Chá»‰ tráº£ lá»i "CÃ“" hoáº·c "TÃ”I KHÃ”NG BIáº¾T"."""

        has_relevant_info = self._get_llm_response(relevance_prompt).strip().upper()
        
        if has_relevant_info == "TÃ”I KHÃ”NG BIáº¾T":
            return {
                "thoughts": [{
                    "step": "Kiá»ƒm tra Ä‘á»™ liÃªn quan",
                    "thought": "ğŸ” Äang Ä‘Ã¡nh giÃ¡ thÃ´ng tin...",
                    "content": "TÃ´i khÃ´ng cÃ³ Ä‘á»§ thÃ´ng tin Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i nÃ y."
                }],
                "final_answer": "TÃ´i lÃ  má»™t chatbot AI vá» dÃ¢n tá»™c, tÃ´i khÃ´ng cÃ³ thÃ´ng tin Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i nÃ y."
            }

        # Náº¿u cÃ³ thÃ´ng tin liÃªn quan, tiáº¿p tá»¥c phÃ¢n tÃ­ch
        thoughts = []
        
        # BÆ°á»›c 1: PhÃ¢n tÃ­ch tá»•ng há»£p
        analysis_prompt = f"""Dá»±a trÃªn context sau:
        {context}
        
        1. PhÃ¢n tÃ­ch cÃ¢u há»i: "{question}"
        2. XÃ¡c Ä‘á»‹nh cÃ¡c Ä‘iá»ƒm chÃ­nh liÃªn quan
        3. TÃ¬m ra má»‘i liÃªn há»‡ giá»¯a cÃ¡c thÃ´ng tin
        4. ÄÆ°a ra cÃ¡c nháº­n Ä‘á»‹nh quan trá»ng

        HÃ£y suy luáº­n má»™t cÃ¡ch logic vÃ  khÃ¡ch quan.
        
        CHÃš Ã: Chá»‰ sá»­ dá»¥ng thÃ´ng tin tá»« context Ä‘Æ°á»£c cung cáº¥p."""

        analysis = self._get_llm_response(analysis_prompt)
        thoughts.append({
            "step": "PhÃ¢n tÃ­ch tá»•ng há»£p",
            "thought": "ğŸ” Äang phÃ¢n tÃ­ch vÃ  káº¿t ná»‘i thÃ´ng tin...",
            "content": analysis
        })

        # BÆ°á»›c 2: ÄÆ°a ra káº¿t luáº­n
        conclusion_prompt = f"""Dá»±a trÃªn phÃ¢n tÃ­ch trÃªn:
        {analysis}
        
        HÃ£y Ä‘Æ°a ra cÃ¢u tráº£ lá»i cho cÃ¢u há»i: "{question}"
        
        YÃŠU Cáº¦U:
        - Tráº£ lá»i Ä‘áº§y Ä‘á»§ thÃ´ng tin
        - ÄÆ°a ra káº¿t luáº­n rÃµ rÃ ng, cháº¯c cháº¯n
        - Táº­p trung vÃ o nhá»¯ng Ä‘iá»ƒm chÃ­nh Ä‘Ã£ phÃ¢n tÃ­ch"""

        final_answer = self._get_llm_response(conclusion_prompt)
        
        return {
            "thoughts": thoughts,
            "final_answer": final_answer
        }

    def _get_llm_response(self, prompt: str) -> str:
        try:
            self.model.google_api_key = self.key_manager.get_api_key()
            response = self.model.invoke(prompt)
            # ThÃªm delay ngáº¯n Ä‘á»ƒ ngÆ°á»i dÃ¹ng theo dÃµi Ä‘Æ°á»£c quÃ¡ trÃ¬nh suy nghÄ©
            time.sleep(1.5)
            return response.content
        except Exception as e:
            logging.error(f"Lá»—i khi gá»i LLM: {str(e)}")
            return "ÄÃ£ xáº£y ra lá»—i trong quÃ¡ trÃ¬nh suy luáº­n" 